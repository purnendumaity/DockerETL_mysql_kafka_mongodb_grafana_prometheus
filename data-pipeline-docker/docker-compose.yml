services:
  zookeeper:
    image: confluentinc/cp-zookeeper:7.6.0
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_HEAP_SIZE: 128M              # Minimal memory
    ports:
      - "2181:2181"
    networks:
      - monitoring

  kafka:
    image: confluentinc/cp-kafka:7.6.0
    depends_on:
      - zookeeper
    ports:
      - "9092:9092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_NUM_NETWORK_THREADS: 2          # Reduce thread usage
      KAFKA_NUM_IO_THREADS: 2               # Reduce I/O thread usage
      KAFKA_HEAP_OPTS: "-Xmx256M -Xms128M"  # Reduce Kafka heap size
    networks:
      - monitoring

  mysql:
    image: mysql:8.0-oracle
    restart: always
    ports:
      - "3305:3306"
    environment:
      MYSQL_ROOT_PASSWORD: pass
      MYSQL_DATABASE: airflow_db
      MYSQL_USER: airflow
      MYSQL_PASSWORD: airflow
    volumes:
      - mysql_data:/var/lib/mysql
      - ./mysql/init.sql:/docker-entrypoint-initdb.d/init.sql
    networks:
      - monitoring

  mongodb:
    image: mongo:6.0
    restart: always
    ports:
      - "27016:27017"
    environment:
      MONGO_INITDB_ROOT_USERNAME: root
      MONGO_INITDB_ROOT_PASSWORD: pass
    volumes:
      - ./mongo/init-mongo.js:/docker-entrypoint-initdb.d/init-mongo.js:ro  
      - mongo_data:/data/db
    networks:
      - monitoring

  airflow:
    image: airflow-custom:latest
    depends_on:
      - kafka
      - zookeeper
      - mysql
      - mongodb
    ports:
      - "8081:8080"
    environment:
      - AIRFLOW__CORE__EXECUTOR=LocalExecutor
      - AIRFLOW__CORE__SQL_ALCHEMY_CONN=mysql+mysqlconnector://airflow:airflow@mysql/airflow_db
      - AIRFLOW__WEBSERVER__AUTH_BACKEND=airflow.auth.backend.allow_all
      - AIRFLOW__CORE__PARALLELISM=2               # Limit number of total running tasks
      - AIRFLOW__CORE__DAG_CONCURRENCY=3           # Limit number of tasks per DAG
      - AIRFLOW__CORE__MAX_ACTIVE_RUNS_PER_DAG=1   # Only 1 DAG run active at a time
      - AIRFLOW__SCHEDULER__DAG_DIR_LIST_INTERVAL=60  # Reduce file scan frequency
    command: >
      bash -c "sleep 20 &&
               rm -f /opt/airflow/airflow-webserver.pid &&
               airflow db migrate &&
               airflow webserver"
    volumes:
      - ./dags:/opt/airflow/dags
      - ./kafka/kafka_input:/opt/airflow/kafka_input
      - ./logs:/opt/airflow/logs
      - ./plugins:/opt/airflow/plugins
    networks:
      - monitoring

  airflow-scheduler:
    image: airflow-custom:latest
    depends_on:
      - airflow
      - kafka
      - zookeeper
      - mysql
      - mongodb
    entrypoint: ["/bin/bash", "-c", "sleep 30 && airflow scheduler"]
    environment:
      - AIRFLOW__CORE__EXECUTOR=LocalExecutor
      - AIRFLOW__CORE__SQL_ALCHEMY_CONN=mysql+mysqlconnector://airflow:airflow@mysql/airflow_db
      - AIRFLOW__WEBSERVER__AUTH_BACKEND=airflow.auth.backend.allow_all
      - AIRFLOW__CORE__PARALLELISM=2               # Limit number of total running tasks
      - AIRFLOW__CORE__DAG_CONCURRENCY=3           # Limit number of tasks per DAG
      - AIRFLOW__CORE__MAX_ACTIVE_RUNS_PER_DAG=1   # Only 1 DAG run active at a time
      - AIRFLOW__SCHEDULER__DAG_DIR_LIST_INTERVAL=60  # Reduce file scan frequency
    volumes:
      - ./dags:/opt/airflow/dags
      - ./kafka/kafka_input:/opt/airflow/kafka_input
      - ./logs:/opt/airflow/logs
      - ./plugins:/opt/airflow/plugins
    networks:
      - monitoring

  grafana:
    image: grafana/grafana:latest
    restart: always
    ports:
      - "3000:3000"
    volumes:
      - grafana-storage:/var/lib/grafana
      - ./grafana/dashboards:/etc/grafana/provisioning/dashboards
      - ./grafana/provisioning/dashboards.yaml:/etc/grafana/provisioning/dashboards.yaml
    networks:
      - monitoring

  prometheus:
    image: prom/prometheus:latest
    restart: always
    networks:
    - monitoring
    volumes:
      - ./prometheus:/etc/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
    ports:
      - "9090:9090"
      
  mysql-exporter:
    image: quay.io/prometheus/mysqld-exporter:latest
    restart: always
    networks:
      - monitoring
    ports:
      - "9104:9104"
    command:
      - "--mysqld.username=airflow:airflow"
      - "--mysqld.address=mysql:3306"
    depends_on:
      - mysql
      
  mongodb-exporter:
    image: percona/mongodb_exporter:0.40.0
    container_name: data-pipeline-docker-mongodb-exporter-1
    restart: always
    ports:
      - "9216:9216"
    environment:
      - MONGODB_URI=mongodb://exporter:exporterpassword@mongodb:27017/admin
    networks:
      - monitoring
    depends_on:
      - mongodb

volumes:
  mysql_data:
  mongo_data:
  grafana-storage:
  
networks:
  monitoring:
